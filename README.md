# ğŸ“˜ Atividade III  
*Data:* 23/08/2025  

## ğŸ“‘ ExperiÃªncia PrÃ¡tica â€“ Ã‰tica, Cidadania Digital e Direitos  
*RelatÃ³rio de AnÃ¡lise Ã‰tica*  
*Caso:* ViÃ©s no Sistema de Recrutamento da Amazon  

*Grupo:*  
- Juciara ConceiÃ§Ã£o  
- Leandro Cavalcante  
- Ana Bastos  
- Suzana Marks  

---

## 1. IntroduÃ§Ã£o  
A InteligÃªncia Artificial (IA) tem transformado processos de recrutamento, prometendo eficiÃªncia e imparcialidade.  
No entanto, o caso da Amazon revelou que algoritmos podem reproduzir e amplificar preconceitos existentes.  

Este relatÃ³rio analisa criticamente o dilema Ã©tico envolvido no uso de IA para triagem de currÃ­culos, aplicando um *framework estruturado* para desenvolver uma posiÃ§Ã£o profissional fundamentada.  

---

## 2. Escolha do Caso  
Selecionamos o caso do sistema de recrutamento da *Amazon, que foi descontinuado apÃ³s descobertas de **viÃ©s contra candidaturas femininas*.  

O algoritmo, treinado com dados histÃ³ricos de contrataÃ§Ãµes majoritariamente masculinas, passou a penalizar currÃ­culos com termos associados ao gÃªnero feminino, como â€œwomenâ€™s chess clubâ€ ou â€œfemaleâ€.  

---

## 3. AnÃ¡lise Ã‰tica Estruturada  

### âš– ViÃ©s e JustiÃ§a  

*Tipo de viÃ©s presente:*  
- *ViÃ©s de dados:* os dados de treinamento refletiam uma cultura organizacional masculina.  
- *ViÃ©s algorÃ­tmico:* o modelo aprendeu padrÃµes discriminatÃ³rios e os replicou.  

*Grupos afetados:*  
- Mulheres foram desproporcionalmente prejudicadas, tendo seus currÃ­culos descartados com base em termos relacionados ao gÃªnero.  

*DistribuiÃ§Ã£o de benefÃ­cios e riscos:*  
- O sistema beneficiava candidatos masculinos e perpetuava desigualdades no mercado de trabalho.  

---

## ğŸ“‚ RelatÃ³rio Completo  
ğŸ“„ [Clique aqui para acessar o PDF](COLOQUE_O_LINK_AQUI)  

---
